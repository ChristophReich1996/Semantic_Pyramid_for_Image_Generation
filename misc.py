from typing import List, Tuple, Union

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import random
from skimage.draw import random_shapes
import os
import json


def get_masks_for_training(
        mask_shapes: List[Tuple] =
        [(1, 128, 128), (1, 64, 64), (1, 32, 32), (1, 16, 16), (1, 8, 8), (4096,), (365,)],
        device: str = 'cpu', add_batch_size: bool = False,
        p_random_mask: float = 0.3) -> List[torch.Tensor]:
    '''
    Method returns random masks similar to 3.2. of the paper
    :param mask_shapes: (List[Tuple]) Shapes of the features generated by the vgg16 model
    :param device: (str) Device to store tensor masks
    :param add_batch_size: (bool) If true a batch size is added to each mask
    :param p_random_mask: (float) Probability that a random mask is generated else no mask is utilized
    :return: (List[torch.Tensor]) Generated masks for each feature tensor
    '''
    # Select layer where no masking is used. Every output from the deeper layers get mapped out. Every higher layer gets
    # masked by a random shape
    selected_stage = random.choice(list(range(len(mask_shapes))) + [0, 1])
    # Make masks
    masks = []
    # Apply spatial varying masks
    spatial_varying_masks = (np.random.rand() < p_random_mask) \
                            and (selected_stage < (len(mask_shapes) - 1)) \
                            and (selected_stage > 0)
    # Init random mask
    if spatial_varying_masks:
        random_mask = random_shapes(tuple(reversed(mask_shapes))[selected_stage + 1][1:],
                                    min_shapes=1,
                                    max_shapes=4,
                                    min_size=min(8, tuple(reversed(mask_shapes))[selected_stage + 1][1] // 2),
                                    allow_overlap=True)[0][:, :, 0]
        # Random mask to torch tensor
        random_mask = torch.tensor(random_mask, dtype=torch.float32, device=device)[None, :, :]
        # Change range of mask to [0, 1]
        random_mask = (random_mask == 255.0).float()
    # Loop over all shapes
    for index, mask_shape in enumerate(reversed(mask_shapes)):
        # Case if spatial varying masks are applied after selected stage
        if spatial_varying_masks:
            if index == selected_stage:
                masks.append(torch.ones(mask_shape, dtype=torch.float32, device=device))
            elif index < selected_stage:
                masks.append(torch.zeros(mask_shape, dtype=torch.float32, device=device))
            else:
                masks.append(F.interpolate(random_mask[None], size=mask_shape[1:], mode='nearest')[0])
        # Case if only one stage is selected
        else:
            if index == selected_stage:
                masks.append(torch.ones(mask_shape, dtype=torch.float32, device=device))
            else:
                masks.append(torch.zeros(mask_shape, dtype=torch.float32, device=device))
    # Add batch size dimension
    if add_batch_size:
        for index in range(len(masks)):
            masks[index] = masks[index].unsqueeze(dim=0)
    # Reverse order of masks to match the features of the vgg16 model
    masks.reverse()
    return masks


def get_masks_for_validation(mask_shapes: Tuple[Tuple[int, int, int], ...] =
                             ((1, 128, 128), (1, 64, 64), (1, 32, 32), (1, 16, 16), (1, 8, 8), (4096,),
                              (365,)), device: str = 'cpu', add_batch_size: bool = False) -> List[torch.Tensor]:
    return get_masks_for_inference(stage_index_to_choose=random.choice(range(len(mask_shapes))),
                                   mask_shapes=mask_shapes, device=device, add_batch_size=add_batch_size)


def get_masks_for_inference(stage_index_to_choose: int,
                            mask_shapes: Tuple[Tuple[int, int, int], ...] = (
                                    (1, 128, 128), (1, 64, 64), (1, 32, 32), (1, 16, 16), (1, 8, 8), (4096,), (365,)),
                            device: str = 'cpu',
                            add_batch_size: bool = False) -> List[torch.Tensor]:
    # Init list for masks
    masks = []
    # Loop over all shapes
    for index, mask_shape in enumerate(reversed(mask_shapes)):
        if index == stage_index_to_choose:
            masks.append(torch.ones(mask_shape, dtype=torch.float32, device=device))
        else:
            masks.append(torch.zeros(mask_shape, dtype=torch.float32, device=device))
    # Add batch size dimension
    if add_batch_size:
        for index in range(len(masks)):
            masks[index] = masks[index].unsqueeze(dim=0)
    # Reverse order of masks to match the features of the vgg16 model
    masks.reverse()
    return masks


def normalize_0_1_batch(input: torch.tensor) -> torch.tensor:
    '''
    Normalize a given tensor to a range of [-1, 1]
    :param input: (Torch tensor) Input tensor
    :return: (Torch tensor) Normalized output tensor
    '''
    input_flatten = input.view(input.shape[0], -1)
    return ((input - torch.min(input_flatten, dim=1)[0][:, None, None, None]) / (
            torch.max(input_flatten, dim=1)[0][:, None, None, None] -
            torch.min(input_flatten, dim=1)[0][:, None, None, None]))


def normalize_m1_1_batch(input: torch.tensor) -> torch.tensor:
    '''
    Normalize a given tensor to a range of [-1, 1]
    :param input: (Torch tensor) Input tensor
    :return: (Torch tensor) Normalized output tensor
    '''
    input_flatten = input.view(input.shape[0], -1)
    return 2 * ((input - torch.min(input_flatten, dim=1)[0][:, None, None, None]) / (
            torch.max(input_flatten, dim=1)[0][:, None, None, None] -
            torch.min(input_flatten, dim=1)[0][:, None, None, None])) - 1


class Logger(object):
    """
    Class to log different metrics
    """

    def __init__(self) -> None:
        self.metrics = dict()
        self.hyperparameter = dict()

    def log(self, metric_name: str, value: float) -> None:
        """
        Method writes a given metric value into a dict including list for every metric
        :param metric_name: (str) Name of the metric
        :param value: (float) Value of the metric
        """
        if metric_name in self.metrics:
            self.metrics[metric_name].append(value)
        else:
            self.metrics[metric_name] = [value]

    def save_metrics(self, path: str) -> None:
        """
        Static method to save dict of metrics
        :param metrics: (Dict[str, List[float]]) Dict including metrics
        :param path: (str) Path to save metrics
        :param add_time_to_file_name: (bool) True if time has to be added to filename of every metric
        """
        # Save dict of hyperparameter as json file
        with open(os.path.join(path, 'hyperparameter.txt'), 'w') as json_file:
            json.dump(self.hyperparameter, json_file)
        # Iterate items in metrics dict
        for metric_name, values in self.metrics.items():
            # Convert list of values to torch tensor to use build in save method from torch
            values = torch.tensor(values)
            # Save values
            torch.save(values, os.path.join(path, '{}.pt'.format(metric_name)))
